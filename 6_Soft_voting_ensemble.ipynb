{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from keras import backend as K\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import kfold_keras\n",
    "from helper import extract_moments, filter_guided, prepare_data\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soft voting ensemble\n",
    "this notebook prepares the final model by combining the best one from the previous steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "using the best pre-processing as determined in the earlier steps: Guided filtering and no scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded training 1604\n",
      "loaded test 1604\n"
     ]
    }
   ],
   "source": [
    "data_folder = Path(\"data\")\n",
    "train_file = data_folder / 'train.json'\n",
    "test_file = data_folder / 'test.json'\n",
    "\n",
    "train = pd.read_json(train_file) \n",
    "print('loaded training '+str(len(train)))\n",
    "test = pd.read_json(test_file) \n",
    "print('loaded test '+str(len(train)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load and train the best models\n",
    "### VGG16 transfer learning\n",
    "\n",
    "This best model used the non-augmented data for best results, and achieved the best results after 5 training episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=train['is_iceberg'].values \n",
    "X=prepare_data(train,dim=[0,1,2],filter_function=filter_guided,rnd=False,scale=None)\n",
    "input_shape= X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "aug_param = {'data_format': 'channels_last',\n",
    " 'featurewise_center': False,\n",
    " 'fill_mode': 'nearest',\n",
    " 'horizontal_flip': False,\n",
    " 'rotation_range': 20,\n",
    " 'vertical_flip': True,\n",
    " 'zoom_range': 0.15}\n",
    "datagen = ImageDataGenerator(aug_param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VGG                 :   0%|          | 0/5 [00:00<?, ?it/s]/home/ckrull/anaconda3/lib/python3.6/site-packages/keras/preprocessing/image.py:594: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "VGG                 : 100%|██████████| 5/5 [04:39<00:00, 52.98s/it, Acc=90.7, Epi=43, ROC_AUC=0.969, vloss=0.236]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created ensemble.\n"
     ]
    }
   ],
   "source": [
    "from statoil_models import vgg16_finetune\n",
    "vgg16_model= vgg16_finetune(input_shape)\n",
    "\n",
    "\n",
    "_,vgg16_ensemble= kfold_keras.k_fold_keras_early_stop(vgg16_model,X,y,k=5,name='VGG', batch_size=128,datagen=datagen,\n",
    "                                                  train_at_end=True,patience =20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN small\n",
    "- the small CNN from scratch had single a fully connected layer with 256 nodes, and batch normalization\n",
    "- data augmentation significantly improved the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statoil_models import Simple_CNN,vgg16_finetune\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "aug_param = {'data_format': 'channels_last',\n",
    " 'featurewise_center': False,\n",
    " 'fill_mode': 'nearest',\n",
    " 'horizontal_flip': False,\n",
    " 'rotation_range': 20,\n",
    " 'vertical_flip': True,\n",
    " 'zoom_range': 0.15}\n",
    "\n",
    "small_cnn= Simple_CNN(input_shape,width=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "small_CNN           :   0%|          | 0/5 [00:00<?, ?it/s]/home/ckrull/anaconda3/lib/python3.6/site-packages/keras/preprocessing/image.py:594: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "small_CNN           : 100%|██████████| 5/5 [01:49<00:00, 22.24s/it, Acc=87, Epi=50.8, ROC_AUC=0.949, vloss=0.32]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created ensemble.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(aug_param)\n",
    "_, small_cnn_ensemble = kfold_keras.k_fold_keras_early_stop(small_cnn,X,y,k=5,name='small_CNN',\n",
    "                                                  train_at_end=True,datagen=datagen,patience =20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest on extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=20, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=3000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_exfeat = extract_moments(train)\n",
    "test_exfeat = extract_moments(test)\n",
    "# drop the missing angle values\n",
    "train_angle=train.where(train['inc_angle'] != 'na')\n",
    "y_exfeat=train_angle['is_iceberg'].dropna(how='all').values\n",
    "X_exfeat=train_angle.drop(['is_iceberg','band_1','band_2','id'],axis=1).dropna(how='all').values\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_frst = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=20, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=3000, n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "\n",
    "rnd_frst.fit(X_exfeat,y_exfeat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soft Voting classifier\n",
    "\n",
    "The predictions of the best models are combined by averaging predictions of the 3 best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=prepare_data(test,dim=[0,1,2],filter_function=filter_guided,rnd=False,scale=None)\n",
    "X_exfeat_test = test_exfeat.drop(['band_1','band_2','id'],axis=1).dropna(how='all').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_frst_proba=rnd_frst.predict_proba(X_exfeat_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_proba=small_cnn_ensemble.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_proba=vgg16_ensemble.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_voting= (rnd_frst_proba+np.squeeze(cnn_proba)+np.squeeze(vgg16_proba))/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission=pd.DataFrame({'id':test['id'],'is_iceberg':rnd_frst_proba})\n",
    "submission.to_csv('submission_rnd_frst.csv',index=False)\n",
    "submission=pd.DataFrame({'id':test['id'],'is_iceberg':np.squeeze(cnn_proba)})\n",
    "submission.to_csv('submission_cnn.csv',index=False)\n",
    "submission=pd.DataFrame({'id':test['id'],'is_iceberg':np.squeeze(vgg16_proba)})\n",
    "submission.to_csv('submission_vgg16.csv',index=False)\n",
    "submission=pd.DataFrame({'id':test['id'],'is_iceberg':soft_voting})\n",
    "submission.to_csv('submission_ensemble.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning the score\n",
    "\n",
    "Unfortunately there was a data leak in this Kaggle competition. It came to general knowledge that a given label the tends to have similar values for the incidence angles, both on the testing and training set. To gauge the impact of this leak, we also applied this gained knowledge to our result and resubmitted the test submission. Just by applying the following rules, we were able to improve upon the final score (from 0.309 to 0.2652):\n",
    "\n",
    "- Compare the incidence angle of the testing set instance\n",
    "- if a similar angle exist  and the predictions agree change the label to the one from the training set, and use a high confidence prediction.\n",
    "- If the label do not agree use majority voting to determine a new label, again use the high probabilities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2477 400 5547\n"
     ]
    }
   ],
   "source": [
    "submission_tuned=pd.DataFrame({'id':test['id'],'is_iceberg':soft_voting})\n",
    "max_prob=0.95\n",
    "min_prob=0.05\n",
    "agree=0\n",
    "disagree=0\n",
    "not_changed=0\n",
    "for idx,angle in enumerate(test['inc_angle']):\n",
    "        iceberg=train['is_iceberg'].loc[abs(train_angle['inc_angle'] - angle) < 0.001]\n",
    "        if len(iceberg) > 0:\n",
    "            #if np.mean(iceberg) not in [0.0, 1.0]:\n",
    "                #print(np.mean(iceberg))\n",
    "            is_iceberg = round(np.mean(iceberg))\n",
    "            if round(soft_voting[idx]) == is_iceberg:\n",
    "                agree+=1\n",
    "                submission_tuned.at[idx,'is_iceberg'] =max_prob if is_iceberg else min_prob\n",
    "            else:\n",
    "                if np.mean(iceberg) != 0.5:\n",
    "                    submission_tuned.at[idx,'is_iceberg'] =max_prob if is_iceberg else min_prob\n",
    "                    disagree+=1\n",
    "                else:\n",
    "                    not_changed+=1\n",
    "        else:\n",
    "            not_changed+=1\n",
    "print(agree,disagree,not_changed)\n",
    "submission_tuned.to_csv('submission_ensemble_tuned.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
